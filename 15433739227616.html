<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	Python Scrapy 多页实践 - 木子才的博客
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="木子才的博客" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
				 	<div class="profilepic">
						<img src="muzicoLogo.jpg" style="width:160px;">
					</div>
            	
					
					<h1><a href="index.html">木子才的博客</a></h1>
					<p class="subtitle">木子才菜鸟的空间~</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="_self" href="index.html">首页</a></li>
						
						  <li id=""><a target="_self" href="archives.html">全部文章</a></li>
						
						  <li id=""><a target="_self" href="flutter.html">flutter</a></li>
						
						  <li id=""><a target="_self" href="iOS.html">iOS</a></li>
						
						  <li id=""><a target="_self" href="Vue.html">Vue</a></li>
						
						  <li id=""><a target="_self" href="Python.html">Python</a></li>
						
						  <li id=""><a target="_self" href="Unity.html">Unity</a></li>
						
						  <li id=""><a target="_self" href="React Native.html">React Native</a></li>
						
						  <li id=""><a target="_self" href="nodejs.html">nodejs</a></li>
						
						  <li id=""><a target="_self" href="Qt.html">Qt</a></li>
						
						  <li id=""><a target="_self" href="Xamarin.html">Xamarin</a></li>
						
						  <li id=""><a target="_self" href="友情链接.html">友情链接</a></li>
						
						  <li id=""><a target="_self" href="iOS组件.html">iOS 组件</a></li>
						
						  <li id=""><a target="_self" href="微信小程序.html">微信小程序</a></li>
						
						  <li id=""><a target="_self" href="Swift.html">Swift</a></li>
						
						  <li id=""><a target="_self" href="PHP.html">PHP</a></li>
						
						  <li id=""><a target="_self" href="作品展示.html">作品展示</a></li>
						
						  <li id=""><a target="_self" href="简单语法转OC文件.html">简单语法转OC文件</a></li>
						
						  <li id=""><a target="_self" href="其他.html">其他</a></li>
						
						  <li id=""><a target="_self" href="无题.html">无题</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">










<a target="_blank" class="github" target="_blank" href="https://github.com/yococoxc" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:547153062@qq.com" title="Email">Email</a>

								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">

	<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
		<h1 class="title" itemprop="name">Python Scrapy 多页实践</h1>
		<div class="entry-content" itemprop="articleBody">
			<h3 id="toc_0">目标</h3>

<p>在 《Python Scrapy 单页实践》基础上添加多页遍历获取数据。</p>

<h3 id="toc_1">遇见问题</h3>

<p>其中由于有中文字符串的判断，会遇见这个问题：</p>

<pre><code>UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
</code></pre>

<p>解决方案是添加相应的内容：</p>

<pre><code>import sys

reload(sys)
sys.setdefaultencoding(&#39;utf8&#39;)
</code></pre>

<p>测试过这段代码放哪里都行，感觉还是放头部最好，对代码的整体影响不大。</p>

<h3 id="toc_2">完整代码</h3>

<p>下面是 manhua.py 的代码：</p>

<pre><code># -*- coding: utf-8 -*-
import scrapy
from manhua.items import ManhuaItem

import sys

reload(sys)
sys.setdefaultencoding(&#39;utf8&#39;)


class ManhuaSpider(scrapy.Spider):
    name = &#39;manhua&#39;
    allowed_domains = [&#39;manhua.dmzj.com&#39;]
    start_urls = [&#39;https://manhua.dmzj.com/update_1.shtml&#39;]

    # reload(sys)
    # sys.setdefaultencoding(&#39;utf8&#39;)

    def parse(self, response):
        # reload(sys)
        # sys.setdefaultencoding(&#39;utf8&#39;)

        manhuas = response.xpath(&#39;//div[@class=&quot;boxdiv1&quot;]&#39;)
        for manhua in manhuas:
            # print(&quot;-----&gt;&gt;&gt;&gt;&gt;&gt;&quot;,manhua)
            
            item = ManhuaItem()

            #获取名字
            item[&#39;name&#39;] = manhua.xpath(&#39;./div[@class=&quot;picborder&quot;]/a/@title&#39;).extract()[0]

            #获取链接
            tempHref = manhua.xpath(&#39;./div[@class=&quot;picborder&quot;]/a/@href&#39;).extract()[0]
            tempHrefArr = tempHref.split(&#39;/&#39;)
            #通过链接长度判断
            if len(tempHrefArr) == 2:
                #非国漫的
                item[&#39;uid&#39;] = tempHrefArr[0]
                item[&#39;gm&#39;] = 0
                #item[&#39;href&#39;] = &quot;https://manhua.dmzj.com/&quot; + tempHrefArr[0]
            else:
                #国漫的
                #item[&#39;href&#39;] = tempHref
                item[&#39;gm&#39;] = 1
                tempUid = tempHrefArr[len(tempHrefArr) - 1]
                tempUidArr = tempUid.split(&#39;.&#39;)
                if len(tempUidArr) == 2:
                    item[&#39;uid&#39;] = tempUidArr[0]
                else:
                    item[&#39;uid&#39;] = tempUid

            #获取时间
            test_time = manhua.css(&#39;div.pictext &gt; ul &gt; li.numfont &gt; span::text&#39;)
            if test_time:
                item[&#39;time&#39;] = test_time.extract()[0]
            else:
                item[&#39;time&#39;] = manhua.css(&#39;div.pictext &gt; ul &gt; li.numfont ::text&#39;).extract()[0]

            yield item

        #获取下一页的数据
        next_text_7 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/text()&#39;).extract()[0]
        if next_text_7 == &#39;下一页&#39;:
            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/@href&#39;).extract_first()
            
            if next_url:
                next_url = response.urljoin(next_url)
                yield scrapy.Request(next_url, callback=self.parse)
            else:
                print(&#39;不是7&#39;)
        else:
            next_text_9 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/text()&#39;).extract()[0]
            if next_text_9 == &#39;下一页&#39;:
                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/@href&#39;).extract_first()
                if next_url:
                    next_url = response.urljoin(next_url)
                    yield scrapy.Request(next_url, callback=self.parse)
                else:
                    print(&#39;不是9&#39;)
            else:
                next_text_10 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/text()&#39;).extract()[0]
                if next_text_10 == &#39;下一页&#39;:
                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/@href&#39;).extract_first()
                    if next_url:
                        next_url = response.urljoin(next_url)
                        yield scrapy.Request(next_url, callback=self.parse)
                    else:
                        print(&#39;不是10&#39;)
                else:
                    next_text_11 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/text()&#39;).extract()[0]
                    if next_text_11 == &#39;下一页&#39;:
                        next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/@href&#39;).extract_first()
                        if next_url:
                            next_url = response.urljoin(next_url)
                            yield scrapy.Request(next_url, callback=self.parse)
                        else:
                            print(&#39;不是11&#39;)
                    else:
                        next_text_12 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/text()&#39;).extract()[0]
                        if next_text_12 == &#39;下一页&#39;:
                            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/@href&#39;).extract_first()
                            if next_url:
                                next_url = response.urljoin(next_url)
                                yield scrapy.Request(next_url, callback=self.parse)
                            else:
                                print(&#39;不是12&#39;)


</code></pre>

<p>获取下一页的数据的代码，感觉写的很差，就是勉强实现了效果，毕竟对Python基础代码不太熟悉，下次补充更好的代码好了。</p>

<h3 id="toc_3">更新获取下一页的数据的代码</h3>

<pre><code>        #获取下一页的数据
        next_url = &#39;&#39;
        next_text_7 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/text()&#39;).extract()[0]
        if next_text_7 == &#39;下一页&#39;:
            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/@href&#39;).extract_first()
        else:
            next_text_8 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[8]/text()&#39;).extract()[0]
            if next_text_8 == &#39;下一页&#39;:
                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[8]/@href&#39;).extract_first()
            else:
                next_text_9 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/text()&#39;).extract()[0]
                if next_text_9 == &#39;下一页&#39;:
                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/@href&#39;).extract_first()
                else:
                    next_text_10 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/text()&#39;).extract()[0]
                    if next_text_10 == &#39;下一页&#39;:
                        next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/@href&#39;).extract_first()
                    else:
                        next_text_11 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/text()&#39;).extract()[0]
                        if next_text_11 == &#39;下一页&#39;:
                            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/@href&#39;).extract_first()
                        else:
                            next_text_12 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/text()&#39;).extract()[0]
                            if next_text_12 == &#39;下一页&#39;:
                                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/@href&#39;).extract_first()
                            else:
                                next_text_13 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[13]/text()&#39;).extract()[0]
                                if next_text_13 == &#39;下一页&#39;:
                                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[13]/@href&#39;).extract_first()
                                else:
                                    next_url = &#39;&#39;

        if len(next_url) &gt; 0:
            next_url = response.urljoin(next_url)
            yield scrapy.Request(next_url, callback=self.parse)
        
</code></pre>

<h3 id="toc_4">闹着玩的</h3>

<pre><code>        #获取下一页的数据
        next_url = &#39;&#39;
        next_text_1 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[1]/text()&#39;).extract()[0]
        if next_text_1 == &#39;下一页&#39;:
            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[1]/@href&#39;).extract_first()
        else:
            next_text_2 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[2]/text()&#39;).extract()[0]
            if next_text_2 == &#39;下一页&#39;:
                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[2]/@href&#39;).extract_first()
            else:
                next_text_3 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[3]/text()&#39;).extract()[0]
                if next_text_3 == &#39;下一页&#39;:
                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[3]/@href&#39;).extract_first()
                else:
                    next_text_4 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[4]/text()&#39;).extract()[0]
                    if next_text_4 == &#39;下一页&#39;:
                        next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[4]/@href&#39;).extract_first()
                    else:
                        next_text_5 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[5]/text()&#39;).extract()[0]
                        if next_text_5 == &#39;下一页&#39;:
                            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[5]/@href&#39;).extract_first()
                        else:
                            next_text_6 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[6]/text()&#39;).extract()[0]
                            if next_text_6 == &#39;下一页&#39;:
                                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[6]/@href&#39;).extract_first()
                            else:
                                next_text_7 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/text()&#39;).extract()[0]
                                if next_text_7 == &#39;下一页&#39;:
                                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[7]/@href&#39;).extract_first()
                                else:
                                    next_text_8 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[8]/text()&#39;).extract()[0]
                                    if next_text_8 == &#39;下一页&#39;:
                                        next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[8]/@href&#39;).extract_first()
                                    else:
                                        next_text_9 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/text()&#39;).extract()[0]
                                        if next_text_9 == &#39;下一页&#39;:
                                            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[9]/@href&#39;).extract_first()
                                        else:
                                            next_text_10 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/text()&#39;).extract()[0]
                                            if next_text_10 == &#39;下一页&#39;:
                                                next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[10]/@href&#39;).extract_first()
                                            else:
                                                next_text_11 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/text()&#39;).extract()[0]
                                                if next_text_11 == &#39;下一页&#39;:
                                                    next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[11]/@href&#39;).extract_first()
                                                else:
                                                    next_text_12 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/text()&#39;).extract()[0]
                                                    if next_text_12 == &#39;下一页&#39;:
                                                        next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[12]/@href&#39;).extract_first()
                                                    else:
                                                        next_text_13 = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[13]/text()&#39;).extract()[0]
                                                        if next_text_13 == &#39;下一页&#39;:
                                                            next_url = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a[13]/@href&#39;).extract_first()
                                                        else:
                                                            next_url = &#39;&#39;

        if len(next_url) &gt; 0:
            next_url = response.urljoin(next_url)
            yield scrapy.Request(next_url, callback=self.parse)
        
</code></pre>

<h3 id="toc_5">最终获取下一页的数据</h3>

<pre><code>        #获取下一页的数据
        next_url = &#39;&#39;
        pagesas = response.xpath(&#39;//div[@class=&quot;newpic_content&quot;]/div[@class=&quot;pages&quot;]/a&#39;)
        for pagesa in pagesas:
            next_text = pagesa.xpath(&#39;./text()&#39;).extract()[0]
            if next_text == &#39;下一页&#39;:
                next_url = pagesa.xpath(&#39;./@href&#39;).extract_first()
                break

        if len(next_url) &gt; 0:
            next_url = response.urljoin(next_url)
            yield scrapy.Request(next_url, callback=self.parse)
        
</code></pre>

		</div>
	</article>
	<div class="share-comment">
	 

	  

	  

	</div>
</div>
        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    
<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>